# Static, Fuzz and Security Testing

## Index
- [Static Testing](#static-testing)
- [Pattern Matching](#pattern-matching)
- [Syntax Analysis](#syntax-analysis)
- [Static Analysis Performance](#static-analysis-performance)
- [Fuzz Testing](#fuzz-testing)
- [Maximizing Code Coverage](#maximizing-code-coverage)
- [Security Testing](#security-testing)
- [The Secure Software Development Life Cycle (Secure-SDLC)](#the-secure-software-development-life-cycle-secure-sdlc)
- [Facets of Security Testing](#facets-of-security-testing)
- [Static Application Security Testing (SAST)](#static-application-security-testing-sast)
- [Dynamic Application Security Testing (DAST)](#dynamic-application-security-testing-dast)
- [Performance of SAST vs DAST](#performance-of-sast-vs-dast)

## Static Testing
Static testing analyzes code characteristics without actually executing that code. You could say it's more of a code
review than actual code testing. Generally static testing entails checking style and structure, and can be used to
evaluate all possible code paths in the *System Under Test* (SUT). Static testing tools are generally very easy to set
up and are pretty scalable. Examples are `Checkstyle` and `ESLint`.

Generally static analysis means checking the code against a set of pre-defined rules. A few techniques that can be used
to do so are pattern matching (e.g. *Regular Expressions*) and syntax analysis (using *Abstract Syntax Trees*).

## Pattern Matching
Pattern matching is a code checking approach that searching for pre-defined patterns in code. RegEx is a sequence of
characters that can be used to define such a pattern. A RegEx engine is generally a state machine (also called **Finite
State Automaton**) that performs certain transitions whenever it reads a character, until none remain. The final state
will then determine whether a pattern was found or not.

Note that automata RegEx is **not** exactly the same as the RegEx you find in programming. Automata RegEx can not do any
looks aheads. This means that `.*bug` would not match `bad bug` in Automata RegEx, eventhough it does in normal regex.
This is because the `b` in the given pattern would match the `b` in `bad`, causing it to fail once it sees an a while it
was expecting a `u`.

One big downside to regular expressions is that there is no way to count. If you want to match a pattern three times you
will simply have to repeat that pattern three times and use that as your pattern. Regular expressions also don't take
semantics into account. If you wanted to remove any active print statements in your code, you would not be able to do
this as any print statements that you had already disabled in your code (with an if statement) would also be detected as
a print statement as subsequently removed. You can't have regex check whether the print statement is active, as you can
write your if statement in any way you want.

## Syntax Analysis
A more advanced code checking approach, that can detect which print statements are used and which are not, is syntax
analysis. Syntax analysis works by constructing a *Parse Tree* of the code, where a stream of individual characters is
used to interpret code, forming a tree.

An abstract version of a parse tree is an **Abstract Syntax Tree**, or an AST. It is very similar to a normal parse
tree; the main difference is that syntax-related characters are omitted.

Static analysis tools use ASTs and a rule-set to check for rule violations. 

## Static Analysis Performance
Generally static analysis produces *sound results*, meaning that there are no false negatives. This is because the tools
that allow for static analysis can analyze the whole codebase and interpret the entire code. This gives them the ability
to follow paths and see where they will end up.

Because static analysis brings sound results, you should in theory be able to use them to find vulnerabilities in your
code. This is not the case though as not all possible paths in your code will ever be taken - some just never happen
when actually executing the code (e.g. `if (false)`). Taking this into account, you get *completeness*, which ensures no
false positives, while soundness ensures no false negatives.

## Fuzz Testing
Fuzzing is a popular form of dynamic testing that can be used to automatically generate complex test cases. These test
cases are generated by bombarding the SUT with random inputs in the hopes of it crashing. This crash can be caused by:
1. Failing assertions;
2. Memory leaks;
3. Improper error handling.

It is generally a successful way of discovering bugs in software.

**Random fuzzing** is the most primitive type of fuzz testing, where no assumptions of the type of input are made. This
makes it much less efficient than other techniques, hence in practice some form of *structured input* is used.

There are two way of generating fuzzing test cases:
1. **Mutation-based fuzzing** - create permutations of example inputs. Characters can be added or replaced to inputs;
2. **Generation-based fuzzing** - also known as protocol fuzzing, takes the input format and protocol specification of
the SUT into consideration while generating test cases. Generative fuzzers take a data model as input which will tell it
how to format the inputs it should generate. An example could be an application only allowing `JPEG` inputs.

Generative fuzzers are more difficult to set up compared to mutation fuzzers, as they require a data model. They do,
however, generate better test cases.

## Maximizing Code Coverage
Maximizing the amount of code that is covered by test cases can pose a challenge no matter how many tests you write. You
want to make sure that all your code is tested, and fuzz testing can help you with that. Fuzzing can generate wildly
diverse test cases, but this can take time. There are a few ways of minimizing this time, though:
1. Multiple tools
2. Telemetry as heuristics;
3. Symbolic execution.

### Multiple Tools
This is as simple as just running multiple fuzzing tools. Each fuzzing tool works in a slightly different manner, so
each tool you run will generate different sets of inputs.

### Telemetry as Heuristics
If the structure of your code is known, you can apply some form of analysis to improve the generated test cases. If you
apply a heuristic based on branch coverage, you can cover many more paths than you would be able to using a heuristic
based on statement coverage. While telemetry testing doesn't help with the generation of inputs directly, it can help
you ensure that the generated inputs improve your code coverage.

### Symbolic Execution
Potential values of variables that will allow the program to reach a desired path are called **symbolic variables**.
We assign **symbolic values** to these variables so we don't have to enumerate through all values that fit the required
format. We can then construct the formula of a **path predicate**, that answers the question: *Given the path
constraints, is there any input that satisfies the path predicate?*. We can then simply only fuzz the values for which
this predicate holds. A popular tool for this is Z3, which we already used before in during Reasoning & Logic. You can
provide Z3 with path constraints, and it will return all possible combinations of values that satisfy these constraints.
This output can be used as input for generative or mutative fuzzers to optimally test various code paths of your SUT.

In short, you can use combinatorial solvers to compute exactly which values lead to which paths being taken. You can use
this information to fuzz certain paths, or ensure that your generated test cases cover all paths.

## Security Testing
You already know what software testing is, but security testing has not yet been covered. The goal of software testing
is to check the correctness of your implementation, the goal of security testing is to find vulnerabilities that could
potentially allow intruders to make the software behave insecurely. An example of such behavior was found in the
*Signal* messaging app, where specific messages allowed intruders to execute and send files on your drive. Security
testing is all about finding and preventing such vulnerabilities.

Just like traditional testing, security testing does not ensure that your systems are 100% secure. New exploits that
manage to break even the best-tested servers can pop up at any time. This is why security testing is not something you
should do just once, but something you should do often, and should be incorporated into the software development
lifecycle. This ensures that as your software is growing, so does its security.

Security testers are always racing against attacks that intend to use possible exploits to ensure that they can't. A
system can be seen as a water balloon, where a needle (an exploit) can pop the balloon whenever it is possible for it to
do so. From this metaphor follows that you should make your attack surface as small as possible; a smaller balloon is
harder to be popped than a large balloon.

### Java Vulnerabilities
Java, like any other programming language, is not immune to security issues. While it might be easier to secure a Java
application due to its sandboxed nature in the Java Virtual Machine, many new vulnerabilities are found every year.
Potential vulnerabilities could be:
1. Code injection;
2. Type confusion;
3. Buffer overflow;
4. Arbitrary Code Execution (ACE);
5. Remote Code Execution (RCE).

#### Code Injection
Code injection can happen when your code directly evaluates some user input. In Javascript, the `eval` method allows you
to interpret and execute a string as Javascript, so this method should never be used to evaluate user input. In Java,
`Class.forName` can be used to find a class with a name that matches the input string. While it might seem less prone
to abuse than Javascript's `eval` method, it can surely be used to exploit your system when given user input.

#### Type Confusion
In Java, different objects will have different permissions. For example, only children of classes will be able to access
private/protected attributes of their superclass. When you cast some object to some class, you're giving that object
permission to access these attributes. The trouble begins when you are typecasting objects to the wrong classes. This
vulnerability was present in the `tryfinally()` method in the Reflection API of Hibernate, where attackers could cast
objects into arbitrary types with varying privileges. This code example from the book explains it pretty well:
```java
class Cast1 extends Throwable {
  Object lemon;
}

class Cast2 extends Throwable {
  Lime lime;
}

public static void throwEx() throws Throwable {
  throw new Cast1();
}

public static void handleEx(Cast2 e) {
  e.lime.makeLimenade();
}
```

In older versions of Java, the thrown `Cast1` would automatically be cast to a `Cast2` when used as input for
`handleEx`, so in this case attackers would be able to execute `Cast1.lime.makeLimenade()`. In this example that would
not make sense, as `Cast` does not have a lime attribute, but there are certainly cases where this can be abused.

In a real-world setting, an attacker could use this vulnerability to bypass the Java Security Managed (**JSM**) and to
disable it, allowing them to use other exploits in order to do whatever they want.

#### Arbitrary Code Execution (ACE)
While Java *does* automatically handle memory, it's still prone to buffer overflows. An example was found in an earlier
version of a GIF library in the Sun JVM, where you could create a GIF with a width of 0 to instantly cause a buffer
overflow, as the buffer was 0 bytes long. This buffer overflow could cause the instruction pointer to be corrupted,
resulting in ACE.

Similarly, the XStream XML deserialization library could cause the instruction pointer to start executing code from
arbitrary memory locations. This location could potentially be controller by an attacker.

When ACE is triggered remotely, it's called Remote Code Execution (RCE). The principle is exactly the same, but the
means of triggering it is different - one is internal while the other is external.

An Oracle report in 2018 stated that most of Java's vulnerabilities can be remotely exploited, which is a very bad thing
considering 3 billion devices run Java worldwide.

## The Secure Software Development Life Cycle (Secure-SDLC)
Security testing is a type of non-functional testing; just like static testing no code is actually executed. Lack of
security can have devastating effects, so the pragmatic approach is to incorperate security testing in each phase of the
SDLC.

This picture from the book shows the SDLC:
![](https://sttp.site/chapters/non-functional-testing/img/security-testing/ssdlc.png)

In phase one, you should asses what potential abuse cases might be in order to know which protections should be in
place. In phase two, you should look into the potential threats, attackers, etc. In phases three and four, plans of the
application should include insights from the attacker model and abuse cases.

The actual testing is vital in phase five, and code should be reviewed from the perspective of attackers. Finally, in
phase six, developers should keep an eye on the CVE database and update vulnerable components in the application. 

Currently, most companies only do *penetration testing*. This on its own is not great, as this leaves security testing
to the very end of the SDLC. Also, penetration testing considers your application a black box, making it hard to find
cases where individual components might cause trouble.

## Facets of Security Testing
Security testing is a very broad term, but is classified as follows:

| |White-box|Black-box|
|---|---|---|
|**Static Application Security Testing**|Code checking, pattern matching, ASTs, CFGs, DFDs||
|**Dynamic Application Security Testing**|Tainting, dynamic validation, symbolic execution|Penetration testing, reverse engineering, behavioral analysis, fuzzing|

### Quality Assessment Criteria
There are a few ways of assessing the quality of testing tools. First off, there should be a balance between soundness
and completeness. Soundness is needed because you don't want false negatives, and completeness is needed because you
want to prevent false positives. In a perfect world both would be achieved, but we don't live in that world, so we
compromise between the two.

Ideal testing tools are interpretable, making it easy to trace issues to their cause, and scalable, meaning that it can
be used to test large-scale applications.

## Static Application Security Testing (SAST)
SAST is just another form as static testing, but for security. SAST techniques aim to find security bugs without running
actual code. This, of course, has its limitations, but can be great for finding issues like SQL Injection or basic XSS.

It is generally very fast when compared to DAST, and is not limited to only code checking. Any approach that does not
involve running code is valid, so you could also create a Control-Flow Graph and see how worst-case scenarios would pan
out. If you don't like what you see you can make changes in order to make your worst-case scenario better. This is
called **Risk-based Testing**, and can be done both statically and dynamically. In short, it's a business-level process
where abuse cases are modeled using threat modelling.

There are many SAST techniques with different use cases.

### Code Checking
Code checking can be done in multiple ways; pattern matching and static analysis using ASTs.

#### Pattern Matching
Pattern matching is rather simplistic, as it does not attempt to interpret the code but instead looks for patterns of
characters. This obviously greatly limits its huge case, but it's a great solution for finding misconfigurations, bad
imports, or calls to dangerous functions that could enable things like code injection.

#### Static Analysis using ASTs
ASTs can be used to interpret code. This makes it possible for testing tools to walk through your code, taking each
path, and seeing what security rules it violates. You could for instance specify how the `printf` function should be
used to ensure that it's always used appropriately (printf is vulnerable to RCE/ACE).

### Structural Testing
Structural testing can be used to ensure that interactions between blocks of code are valid.

#### Control-Flow Graphs
CFGs can be used to map each path through your code your application might take. This makes it possible to graphically
pinpoint possible vulnerability-prone areas. These areas could include unintended transitions between parts of your code
or certain blocks of code being unreachable.

CFGs have previously been used to detect the maliciousness of an application. They can be used to detect self-mutating
malware by comparing the CFG of that malware to CFGs of other known malwares. CFGs are pretty much ideal for checking
for plagiarism in code, the structure of code doesn't change when you simply rename variables.

#### Data Flow Diagram (DFD)
Data flow diagrams are built on top of CFGs and show how data traverses through a program. DFDs track all possible
values a variable might have at a point of time during code execution. This can be used to detect sanitization problems
that could potentially cause ACE or code injection.

Data Flow Analysis (DFA) works by tracking a **source** (a user-controlled variable). The source can be tainted by
**sinks**, which are all other variables. When sources are mixed with sinks, the only way to ensure that this source
does not become tainted, is to validate the sink.

In DFA, we prove that no tainted data is used, and that no untainted data is expected - all data is validated before
being used. Any direct path between a source and sink is a violation, and should be fixed when indicated during DFA.

This example from the book shows a real case that can be detected using DFA:
```java
/* Uses bad source and bad sink */
public void bad(HttpServletRequest request, HttpServletResponse response)
  throws Throwable {

  String data;

  /* Potential flaw: Read data from a queryString using getParameter */
  data  = request.getParameter("name");

  if (data != null) {
    /* Potential flaw: Display of data in web pages after using
    * replaceAll() to remove script tags,
    * will still allow XSS with string like <scr<script>ipt>. */
    response.getWriter().println("<br>bad(): data = " +
        data.replaceAll("(<script>)", ""));
  }
}
```

You can also perform DFA dynamically (Taint Analysis), where tainted variables are tracked in memory.

##### Reaching Definitions Analysis
One application of DFA is called **Reaching Definitions**. It identifies all possible values of a variable. For security
purposes it can also detect Type Confusion and use of variables after their memory has been freed.

RDA works by creating a CFG. You can then see how data changes per block and construct a table based on this. A for
loop, for instance, usually contains `i++` in the `i` column. It is not possible to know exactly which values are
assigned to each variable during the loop when using static analysis, as knowing when the loop terminates is an
undecidable problem (= the halting problem). The column of a variable in the previously described table is also not
always perfect, as some values are simply impossible during runtime. Hence, this column represents an overestimation of
the values a variable can take on; RDA is sound but incomplete.

An example table:

|code blocks|a|b|
|:---:|:---:|:---:|
|b1|6|3|
|b2|a--|b - a|
|b3| |b|

This would create the following possible values per variable after the loop has ended:
```
a = { 6, 5, 4, 3, 2, 1, 0, -1, ... } // start at 6, then decrements by 1 indefinitely
b = { 3, 2, 1, 0, -1, 2, -3, ... } U { 4, 5, 6, 7, ... } = Z
```

Note that `a` starts at 6 and can go down in steps of one indefinitely according to our RDA. `b` starts at 3 can be
decremented by `a`. Since `a` starts at 6, the lowest value `b` can take on is `3 - 6 = -3`. `a` goes down indefinitely,
though, so `b` can take on any value above `-3`.

This table could correspond to the following code, which computes `b - a(a+1)/2`:
```java
int a = 6;
int b = 3;
while (a > 0) {
    b -= a--;
}
return b;
```

When you know what this code does it is quite obvious that the only possible value for `a` at the end of the code is 0,
but static analysis can't determine that. The same goes for `b`, we know that it should be `-18` in the end, because
that's simply the result of `b - a(a+1)/2` with `a = 6`, `b = 3`. Static analysis determined that `b` could be any
integer, though.

The previously shown table is of course more comprehensive than others you might see, as most variables have pretty
clearly defined extremes (no `a++` or `b - a` results in non-infinite sets for `a` and `b`).

## Dynamic Application Security Testing (DAST)
Unlike static analysis, dynamic analysis actually runs code. Dynamic analysis can take the form of *dynamic application
security testing*. A common example is penetration testing, where you get someone to purposefully try to crack your
application's security from the outside. This could involve crafting custom API calls, etc. All in all, it requires
a running application and can detect issues that static analysis would not have detected.

An example of an issue that only dynamic analysis can detect is Denial of Service (DoS). Malicious parties could make
specific calls to your application to make it do computationally expensive work, slowing down your service or even
taking it down. This clearly requires code to run.

DAST tools typically do not have access to the source code, so they can only test functional code paths (= less sound
than SAST) These tools do need to know how to trigger these paths, though. This makes DAST harder to set up than SAST,
however search-based algorithms have been proposed to maximize code coverage without much manual work. 

### Taint Analysis
As previously discussed, taint analysis is a dynamic version of data flow analysis. Variables can be tracker through
memory to ensure they don't become tainted. Taint analysis works using a *taint table*. This table records tainted
values and analyses how these values propagate throughout the code, and how these values affect other values or
statements (e.g. if statements). To enable tainting, **code instrumentation** is done. This means adding hooks to
variables of interest in order to be able to track them.

A tool that allows this is *Panorama*, which can detect malicious software like keyloggers and spyware using dynamic
taint analysis. It works on the intuition that benign software does not interfere with OS-specific data transfer (like
keystrokes being reported by your keyboard drivers). Malicious software also tends to share information with third
parties. This can also be detected using taint analysis.

### Dynamic Validation
Dynamic validation applies functional testing on the SUT based on the SUT's specification. It is rather simple as it
only tests against pre-defined specifications, so thinking of abuse cases (and methods) is vital when using dynamic
validation. Dynamic validation is similar to **model checking** as they both require some specification to work, but
model checking differs in the fact that it builds a model based on the SUT (as it learns about it).

Model checking can codify security vulnerabilities as safety properties, and analyse processes to ensure these
properties always hold to prevent abuse.

### Penetration Testing
Arguably the best-known DAST method is penetration testing. It is a block-box testing technique where adversaries (or
people that emulate being adversaries) will try to abuse the system. Depending on the knowledge of the attacker
penetration Penetration testing can also be white-box, though. Pen testing is sometimes referred to as *ethical
hacking*. It is different from other DAST techniques as this technique purely focuses on the perspective of attackers.

Pen testing checks the SUT in an e2e fashion, so the fully implemented application is tested as opposed to individual
components. *MetaSploit* is an example of a powerful pen testing framework. Most of these frameworks contain
*Vulnerability Scanners* that can run (custom) exploits, and *Password Crackers* that attempt to access the system using
brute-force or dictionary password attempts.

### Behavioral Analysis
Behavioral Analysis involves gaining insight about the software by generating behavioral logs. Since a code base usually
contains of third-party code, it is important perform this type of analysis to ensure that these third-party code blocks
are not malicious or buggy.

You can compare behavioral logs to behavioral logs that are known to be normal in order to spot faults or bugs. An
example of behavioral analysis is done in JPacman, where there are two score modules of which one is malicious. They
both generate different behavioral logs, so comparing them can be a great way to find out which one is malicious, and
where the abuse is happening. These behavioral logs can be generated by running a fuzzer against your software.

### Reverse Engineering
Reverse Engineering is a black-box technique in which you try to figure out the internal structure of an application.
This information can be very valuable to malicious parties, as it can turn a black-box technique whiter. RE is not
really a testing technique, but can help you convert legacy software into a modern version, or understanding a
competitor's product. One way of reverse engineering is using behavioral logs; an effective logger can tell you much
about how a piece of software works internally, and can even be applied to automatically create a model of the SUT which
you can then apply other testing methods on.

### Fuzzing
As previously discussed, fuzzing is a testing technique that involves generating inputs to test your SUT against. You
are trying to make your tests fail, but to get useful results you preferably only use valid values as input. This
creates the distinction between mutation-based fuzzers and generative fuzzers.

Fuzzers are widely used, and can be quite effective when applied correctly (it can take quite some time though!).

## Performance of SAST vs DAST
SAST is generally faster as you don't have to run actual code. It also doesn't involve mass-generating/executing tests
like many DAST techniques do. Since SAST does not run the actual code, its performance quality-wise is worse, though.
The fact that almost all software uses third-party modules makes this an even bigger issue. DAST is more black-box, so
less efficient time-wise, but will be more accurate when attempting to emulate potential adversaries, but also makes it
less scalable as finding issues in a large system will take a very long time. 
