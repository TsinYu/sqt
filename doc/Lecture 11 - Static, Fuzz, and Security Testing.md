# Static, Fuzz and Security Testing

## Index
- [Static Testing](#static-testing)
- [Pattern Matching](#pattern-matching)
- [Syntax Analysis](#syntax-analysis)
- [Static Analysis Performance](#static-analysis-performance)
- [Fuzz Testing](#fuzz-testing)
- [Maximizing Code Coverage](#maximizing-code-coverage)

## Static Testing
Static testing analyzes code characteristics without actually executing that code. You could say it's more of a code
review than actual code testing. Generally static testing entails checking style and structure, and can be used to
evaluate all possible code paths in the *System Under Test* (SUT). Static testing tools are generally very easy to set
up and are pretty scalable. Examples are `Checkstyle` and `ESLint`.

Generally static analysis means checking the code against a set of pre-defined rules. A few techniques that can be used
to do so are pattern matching (e.g. *Regular Expressions*) and syntax analysis (using *Abstract Syntax Trees*).

## Pattern Matching
Pattern matching is a code checking approach that searching for pre-defined patterns in code. RegEx is a sequence of
characters that can be used to define such a pattern. A RegEx engine is generally a state machine (also called **Finite
State Automaton**) that performs certain transitions whenever it reads a character, until none remain. The final state
will then determine whether a pattern was found or not.

Note that automata RegEx is **not** exactly the same as the RegEx you find in programming. Automata RegEx can not do any
looks aheads. This means that `.*bug` would not match `bad bug` in Automata RegEx, eventhough it does in normal regex.
This is because the `b` in the given pattern would match the `b` in `bad`, causing it to fail once it sees an a while it
was expecting a `u`.

One big downside to regular expressions is that there is no way to count. If you want to match a pattern three times you
will simply have to repeat that pattern three times and use that as your pattern. Regular expressions also don't take
semantics into account. If you wanted to remove any active print statements in your code, you would not be able to do
this as any print statements that you had already disabled in your code (with an if statement) would also be detected as
a print statement as subsequently removed. You can't have regex check whether the print statement is active, as you can
write your if statement in any way you want.

## Syntax Analysis
A more advanced code checking approach, that can detect which print statements are used and which are not, is syntax
analysis. Syntax analysis works by constructing a *Parse Tree* of the code, where a stream of individual characters is
used to interpret code, forming a tree.

An abstract version of a parse tree is an **Abstract Syntax Tree**, or an AST. It is very similar to a normal parse
tree; the main difference is that syntax-related characters are omitted.

Static analysis tools use ASTs and a rule-set to check for rule violations. 

## Static Analysis Performance
Generally static analysis produces *sound results*, meaning that there are no false negatives. This is because the tools
that allow for static analysis can analyze the whole codebase and interpret the entire code. This gives them the ability
to follow paths and see where they will end up.

Because static analysis brings sound results, you should in theory be able to use them to find vulnerabilities in your
code. This is not the case though as not all possible paths in your code will ever be taken - some just never happen
when actually executing the code (e.g. `if (false)`). Taken this into account, you get *completeness*, which consists of
all paths that will actually be taken. This is a subset of sound.

## Fuzz Testing
Fuzzing is a popular form of dynamic testing that can be used to automatically generate complex test cases. These test
cases are generated by bombarding the SUT with random inputs in the hopes of it crashing. This crash can be caused by:
1. Failing assertions;
2. Memory leaks;
3. Improper error handling.

It is generally a successful way of discovering bugs in software.

**Random fuzzing** is the most primitive type of fuzz testing, where no assumptions of the type of input are made. This
makes it much less efficient than other techniques, hence in practice some form of *structured input* is used.

There are two way of generating fuzzing test cases:
1. **Mutation-based fuzzing** - create permutations of example inputs. Characters can be added or replaced to inputs;
2. **Generation-based fuzzing** - also known as protocol fuzzing, takes the input format and protocol specification of
the SUT into consideration while generating test cases. Generative fuzzers take a data model as input which will tell it
how to format the inputs it should generate. An example could be an application only allowing `JPEG` inputs.

Generative fuzzers are more difficult to set up compared to mutation fuzzers, as they require a data model. They do,
however, generate better test cases.

## Maximizing Code Coverage
Maximizing the amount of code that is covered by test cases can pose a challenge no matter how many tests you write. You
want to make sure that all your code is tested, and fuzz testing can help you with that. Fuzzing can generate wildly
diverse test cases, but this can take time. There are a few ways of minimizing this time, though:
1. Multiple tools
2. Telemetry as heuristics;
3. Symbolic execution.

### Multiple Tools
This is as simple as just running multiple fuzzing tools. Each fuzzing tool works in a slightly different manner, so
each tool you run will generate different sets of inputs.

### Telemetry as Heuristics
If the structure of your code is known, you can apply some form of analysis to improve the generated test cases. If you
apply a heuristic based on branch coverage, you can cover many more paths than you would be able to using a heuristic
based on statement coverage. While telemetry testing doesn't help with the generation of inputs directly, it can help
you ensure that the generated inputs improve your code coverage.

### Symbolic Execution
Potential values of variables that will allow the program to reach a desired path are called **symbolic variables**.
We assign **symbolic values** to these variables so we don't have to enumerate through all values that fit the required
format. We can then construct the formula of a **path predicate**, that answers the question: *Given the path
constraints, is there any input that satisfies the path predicate?*. We can then simply only fuzz the values for which
this predicate holds. A popular tool for this is Z3, which we already used before in during Reasoning & Logic. You can
provide Z3 with path constraints, and it will return all possible combinations of values that satisfy these constraints.
This output can be used as input for generative or mutative fuzzers to optimally test various code paths of your SUT.

In short, you can use combinatorial solvers to compute exactly which values lead to which paths being taken. You can use
this information to fuzz certain paths, or ensure that your generated test cases cover all paths.
